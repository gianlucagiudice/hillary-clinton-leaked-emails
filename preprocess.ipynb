{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from os.path import join\n",
    "import regex as re\n",
    "import string\n",
    "import seaborn as sns\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "DATA_PATH = 'data/'\n",
    "EMAIL_DATA = 'Emails.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Read dataframe"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NA values in body: 1203.\n",
      "Number of valid email: 6742\n"
     ]
    },
    {
     "data": {
      "text/plain": "    SenderPersonId           MetadataDateSent  \\\nId                                              \n2              NaN  2011-03-03T05:00:00+00:00   \n3             32.0  2012-09-12T04:00:00+00:00   \n5             80.0  2011-03-11T05:00:00+00:00   \n6             80.0  2012-09-12T04:00:00+00:00   \n8             80.0  2011-03-11T05:00:00+00:00   \n\n                                     ExtractedSubject  \\\nId                                                      \n2                                                 NaN   \n3                                   Re: Chris Stevens   \n5                                                 NaN   \n6   Meet The Right Wing Extremist Behind Anti-Musl...   \n8                                                 NaN   \n\n                                    ExtractedBodyText  \nId                                                     \n2   B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...  \n3                                                 Thx  \n5   H <hrod17@clintonemail.com>\\nFriday, March 11,...  \n6   Pis print.\\n-•-...-^\\nH < hrod17@clintonernail...  \n8   H <hrod17@clintonemail.corn>\\nFriday, March 11...  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SenderPersonId</th>\n      <th>MetadataDateSent</th>\n      <th>ExtractedSubject</th>\n      <th>ExtractedBodyText</th>\n    </tr>\n    <tr>\n      <th>Id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>2</th>\n      <td>NaN</td>\n      <td>2011-03-03T05:00:00+00:00</td>\n      <td>NaN</td>\n      <td>B6\\nThursday, March 3, 2011 9:45 PM\\nH: Latest...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>32.0</td>\n      <td>2012-09-12T04:00:00+00:00</td>\n      <td>Re: Chris Stevens</td>\n      <td>Thx</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>80.0</td>\n      <td>2011-03-11T05:00:00+00:00</td>\n      <td>NaN</td>\n      <td>H &lt;hrod17@clintonemail.com&gt;\\nFriday, March 11,...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>80.0</td>\n      <td>2012-09-12T04:00:00+00:00</td>\n      <td>Meet The Right Wing Extremist Behind Anti-Musl...</td>\n      <td>Pis print.\\n-•-...-^\\nH &lt; hrod17@clintonernail...</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>80.0</td>\n      <td>2011-03-11T05:00:00+00:00</td>\n      <td>NaN</td>\n      <td>H &lt;hrod17@clintonemail.corn&gt;\\nFriday, March 11...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(join(DATA_PATH, EMAIL_DATA))\n",
    "\n",
    "# Subset useful fields\n",
    "df = df[['Id', 'SenderPersonId', 'MetadataDateSent',\n",
    "         'ExtractedSubject', 'ExtractedBodyText']]\n",
    "df = df.astype({'Id': int})\n",
    "df = df.set_index('Id')\n",
    "\n",
    "# Drop na values based on Extracted body\n",
    "len_before = len(df)\n",
    "df = df[df['ExtractedBodyText'].notna()]\n",
    "print(f\"Number of NA values in body: {len_before - len(df)}.\\nNumber of valid email: {len(df)}\")\n",
    "df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Raw:\n",
      "Brennan, John 0.\n",
      "Subject: RE: Google and YouTube\n",
      "Sue just called back and the block will stay through Monday. They will not/not be unblocking it before then.\n",
      "Nora Toiv\n",
      "Office of the Secretary\n",
      "202-647-8633\n",
      ">>> Cleaned:\n",
      "brennan, john 0.\n",
      "subject: sue just called back and the block will stay through monday. they will not/not be unblocking it before then.\n",
      "nora toiv\n",
      "office of the secretary\n",
      "202-647-8633\n"
     ]
    }
   ],
   "source": [
    "# Body preprocessing\n",
    "def clean_body(body):\n",
    "    days = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "    email_header = re.compile(r'.+[^<]+<[^>]+>', re.IGNORECASE)\n",
    "    re_header = re.compile(r'(Delivered:\\s+)?RE:[^\\n]+\\n', re.IGNORECASE)\n",
    "    fw_header = re.compile(r'FW:[^\\n]+\\n', re.IGNORECASE)\n",
    "    date_header = re.compile(r'\\w+,\\s\\w+\\s\\d+,\\s\\d+[^\\n]+\\n', re.IGNORECASE)\n",
    "    # Convert to lowercase\n",
    "    body = body.lower()\n",
    "    # Remove email\n",
    "    body = re.sub(email_header, '', body).strip()\n",
    "    # Remove \"FW:\"\n",
    "    body = re.sub(fw_header, '', body).strip()\n",
    "    # Remove \"RE:\"\n",
    "    body = re.sub(re_header, '', body).strip()\n",
    "    # Remove date\n",
    "    body = re.sub(date_header, '', body).strip()\n",
    "    return body\n",
    "\n",
    "sample = df['ExtractedBodyText'].loc[230]\n",
    "print('>>> Raw:\\n' + sample)\n",
    "print('>>> Cleaned:\\n' + clean_body(sample))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Drop the emails that are too short"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def tokenize_body(body):\n",
    "    tokenized = word_tokenize(body)\n",
    "    # Strip tokens\n",
    "    tokenized = [token.strip() for token in tokenized]\n",
    "\n",
    "    # --------- STRICT RULE ---------\n",
    "    # Strict regex rule\n",
    "    tokenized = [token for token in tokenized if re.match('\\w+', token)]\n",
    "    # --------- STRICT RULE ---------\n",
    "\n",
    "    # Remove punctuation\n",
    "    tokenized = [token for token in tokenized if token not in string.punctuation]\n",
    "    # Remove stopwords\n",
    "    stop = stopwords.words('english') + [':', '.', '@']\n",
    "    tokenized = [token for token in tokenized if token not in stop]\n",
    "    # Remove numbers\n",
    "    tokenized = [token for token in tokenized if not re.search(r'\\d', token)]\n",
    "    return tokenized\n",
    "\n",
    "to_tokenize = clean_body(sample)\n",
    "tokenize_body(to_tokenize)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": 187,
   "outputs": [
    {
     "data": {
      "text/plain": "['brennan',\n 'john',\n 'subject',\n 'sue',\n 'called',\n 'back',\n 'block',\n 'stay',\n 'monday',\n 'not/not',\n 'unblocking',\n 'nora',\n 'toiv',\n 'office',\n 'secretary']"
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "outputs": [],
   "source": [
    "def process_body(body):\n",
    "    body = clean_body(body)\n",
    "    tokenized = tokenize_body(body)\n",
    "    return tokenized\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "outputs": [],
   "source": [
    "df['Tokenized'] = df['ExtractedBodyText'].apply(process_body)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [
    {
     "data": {
      "text/plain": "[18,\n 1,\n 9,\n 40,\n 9,\n 1,\n 11,\n 1,\n 11,\n 1,\n 650,\n 39,\n 62,\n 5,\n 2,\n 1,\n 13,\n 10,\n 3,\n 2,\n 7,\n 0,\n 16,\n 0,\n 2,\n 624,\n 2,\n 1,\n 2,\n 635,\n 11,\n 1,\n 278,\n 5,\n 20,\n 1,\n 5,\n 2,\n 4,\n 1,\n 7,\n 628,\n 7,\n 0,\n 9,\n 8,\n 36,\n 63,\n 14,\n 43,\n 70,\n 482,\n 17,\n 75,\n 6,\n 378,\n 3,\n 4,\n 7,\n 1,\n 2,\n 2,\n 89,\n 302,\n 4,\n 1,\n 123,\n 8,\n 6,\n 3,\n 0,\n 29,\n 59,\n 1,\n 22,\n 530,\n 52,\n 7,\n 16,\n 6,\n 6,\n 8,\n 10,\n 19,\n 84,\n 6,\n 0,\n 20,\n 1,\n 12,\n 4,\n 0,\n 5,\n 1,\n 135,\n 6,\n 4,\n 4,\n 1,\n 2,\n 19,\n 7,\n 1,\n 1,\n 19,\n 1,\n 6,\n 20,\n 55,\n 2,\n 29,\n 962,\n 2,\n 0,\n 1,\n 62,\n 2,\n 3,\n 6,\n 1,\n 2,\n 3,\n 1,\n 0,\n 44,\n 14,\n 8,\n 8,\n 0,\n 1049,\n 37,\n 2,\n 104,\n 214,\n 2,\n 4,\n 1,\n 3,\n 9,\n 7,\n 9,\n 1,\n 299,\n 2,\n 2,\n 4,\n 25,\n 150,\n 33,\n 3,\n 835,\n 595,\n 2,\n 2,\n 4,\n 1,\n 2,\n 114,\n 2,\n 2,\n 7,\n 2,\n 10,\n 2,\n 13,\n 1,\n 2,\n 10,\n 7,\n 1,\n 10,\n 2,\n 9,\n 8,\n 12,\n 16,\n 6,\n 1,\n 689,\n 0,\n 15,\n 1,\n 91,\n 3,\n 231,\n 6832,\n 2,\n 74,\n 1,\n 22,\n 6,\n 2,\n 11,\n 39,\n 22,\n 12,\n 3,\n 0,\n 2,\n 15,\n 259,\n 1,\n 3,\n 2,\n 260,\n 191,\n 22,\n 1,\n 456,\n 3,\n 3,\n 494,\n 43,\n 2,\n 12,\n 11,\n 10,\n 86,\n 11,\n 0,\n 1,\n 1,\n 1,\n 7,\n 7,\n 9,\n 11,\n 29,\n 2,\n 2,\n 9,\n 19,\n 1,\n 3,\n 526,\n 1,\n 722,\n 3,\n 7,\n 533,\n 10,\n 1,\n 22,\n 2,\n 1,\n 3,\n 2,\n 2,\n 5,\n 37,\n 13,\n 29,\n 7,\n 1,\n 21,\n 2,\n 20,\n 31,\n 196,\n 5,\n 35,\n 42,\n 3,\n 2,\n 7,\n 5,\n 9,\n 1,\n 3,\n 10,\n 11,\n 6,\n 1,\n 4,\n 4,\n 20,\n 1,\n 1,\n 6,\n 6,\n 13,\n 16,\n 4,\n 3,\n 2,\n 1,\n 7,\n 1,\n 1,\n 12,\n 13,\n 14,\n 18,\n 7,\n 28,\n 25,\n 3,\n 4,\n 6,\n 2,\n 44,\n 8,\n 4,\n 5,\n 1,\n 10,\n 75,\n 4,\n 1,\n 1,\n 1,\n 13,\n 5,\n 8,\n 3,\n 3,\n 5,\n 6,\n 17,\n 1,\n 4,\n 4,\n 1,\n 2,\n 4,\n 8,\n 5,\n 1,\n 14,\n 4,\n 4,\n 4,\n 14,\n 3,\n 6,\n 20,\n 5,\n 3,\n 7,\n 6,\n 6,\n 9,\n 4,\n 1,\n 21,\n 4,\n 5,\n 12,\n 16,\n 1,\n 1,\n 2,\n 3,\n 1,\n 21,\n 19,\n 15,\n 8,\n 1,\n 1,\n 7,\n 12,\n 1,\n 3,\n 43,\n 15,\n 8,\n 1,\n 2,\n 2,\n 5,\n 26,\n 6,\n 1,\n 3,\n 31,\n 4,\n 4,\n 2,\n 3,\n 3,\n 5,\n 2,\n 6,\n 4,\n 6,\n 4,\n 6,\n 11,\n 1,\n 2,\n 25,\n 25,\n 23,\n 2,\n 4,\n 21,\n 9,\n 1,\n 8,\n 9,\n 12,\n 10,\n 8,\n 1,\n 9,\n 4,\n 1,\n 4,\n 3,\n 14,\n 4,\n 21,\n 7,\n 8,\n 7,\n 7,\n 15,\n 6,\n 8,\n 2,\n 14,\n 4,\n 1,\n 7,\n 18,\n 6,\n 1,\n 4,\n 8,\n 6,\n 6,\n 11,\n 8,\n 2,\n 1,\n 3,\n 3,\n 44,\n 6,\n 4,\n 11,\n 1,\n 4,\n 1,\n 10,\n 8,\n 7,\n 42,\n 12,\n 24,\n 1,\n 2,\n 7,\n 7,\n 25,\n 4,\n 8,\n 30,\n 2,\n 9,\n 8,\n 3,\n 2,\n 10,\n 0,\n 5,\n 9,\n 2,\n 3,\n 1,\n 1,\n 6,\n 1,\n 29,\n 14,\n 7,\n 4,\n 7,\n 1,\n 12,\n 1,\n 9,\n 3,\n 6,\n 1,\n 2,\n 3,\n 2,\n 3,\n 9,\n 2,\n 3,\n 20,\n 7,\n 3,\n 33,\n 1,\n 15,\n 3,\n 2,\n 13,\n 5,\n 4,\n 5,\n 1,\n 12,\n 13,\n 8,\n 7,\n 2,\n 14,\n 3,\n 9,\n 2,\n 1,\n 1,\n 7,\n 2,\n 18,\n 4,\n 6,\n 6,\n 1,\n 7,\n 10,\n 13,\n 2,\n 10,\n 3,\n 11,\n 2,\n 21,\n 14,\n 4,\n 7,\n 8,\n 4,\n 1,\n 1,\n 1,\n 4,\n 5,\n 8,\n 1,\n 2,\n 7,\n 1,\n 36,\n 15,\n 9,\n 2,\n 8,\n 3,\n 6,\n 3,\n 10,\n 2,\n 5,\n 4,\n 4,\n 13,\n 8,\n 2,\n 8,\n 15,\n 11,\n 8,\n 4,\n 1,\n 13,\n 4,\n 13,\n 9,\n 2,\n 15,\n 11,\n 8,\n 4,\n 1,\n 4,\n 10,\n 1,\n 1,\n 8,\n 1,\n 11,\n 8,\n 2,\n 10,\n 9,\n 12,\n 6,\n 2,\n 2,\n 3,\n 11,\n 0,\n 9,\n 42,\n 11,\n 9,\n 8,\n 4,\n 11,\n 5,\n 15,\n 9,\n 2,\n 8,\n 25,\n 2,\n 4,\n 6,\n 5,\n 4,\n 4,\n 4,\n 6,\n 7,\n 5,\n 8,\n 12,\n 2,\n 8,\n 13,\n 16,\n 1,\n 22,\n 2,\n 0,\n 3,\n 14,\n 10,\n 2,\n 3,\n 3,\n 6,\n 2,\n 10,\n 1,\n 1,\n 22,\n 29,\n 9,\n 122,\n 1,\n 19,\n 2,\n 5,\n 7,\n 11,\n 9,\n 4,\n 9,\n 1,\n 2,\n 8,\n 12,\n 2,\n 5,\n 1,\n 3,\n 1,\n 14,\n 6,\n 7,\n 3,\n 2,\n 2,\n 2,\n 5,\n 2,\n 4,\n 0,\n 5,\n 5,\n 5,\n 14,\n 5,\n 13,\n 10,\n 6,\n 4,\n 4,\n 1,\n 20,\n 1,\n 4,\n 5,\n 12,\n 1,\n 3,\n 5,\n 50,\n 5,\n 7,\n 5,\n 10,\n 2,\n 10,\n 11,\n 8,\n 2,\n 5,\n 5,\n 3,\n 6,\n 1,\n 6,\n 3,\n 9,\n 11,\n 5,\n 5,\n 18,\n 14,\n 4,\n 3,\n 4,\n 1,\n 16,\n 2,\n 1,\n 7,\n 0,\n 12,\n 9,\n 14,\n 7,\n 5,\n 9,\n 1,\n 11,\n 16,\n 61,\n 9,\n 85,\n 1,\n 2,\n 18,\n 7,\n 2,\n 6,\n 9,\n 2,\n 17,\n 8,\n 12,\n 3,\n 6,\n 2,\n 54,\n 1,\n 1,\n 4,\n 16,\n 6,\n 4,\n 4,\n 4,\n 5,\n 16,\n 9,\n 9,\n 21,\n 2,\n 7,\n 12,\n 2,\n 26,\n 11,\n 5,\n 3,\n 2,\n 4,\n 24,\n 23,\n 1,\n 37,\n 15,\n 2,\n 2,\n 8,\n 7,\n 8,\n 3,\n 15,\n 2,\n 3,\n 13,\n 16,\n 1,\n 21,\n 15,\n 8,\n 4,\n 16,\n 1,\n 6,\n 13,\n 10,\n 14,\n 3,\n 7,\n 4,\n 1,\n 4,\n 1,\n 10,\n 15,\n 3,\n 1,\n 4,\n 9,\n 32,\n 11,\n 11,\n 4,\n 0,\n 20,\n 6,\n 15,\n 2,\n 1,\n 12,\n 8,\n 4,\n 31,\n 3,\n 5,\n 5,\n 2,\n 17,\n 10,\n 11,\n 6,\n 3,\n 19,\n 9,\n 24,\n 11,\n 23,\n 2,\n 42,\n 37,\n 6,\n 2,\n 3,\n 20,\n 5,\n 2,\n 8,\n 8,\n 28,\n 5,\n 3,\n 1,\n 8,\n 47,\n 2,\n 8,\n 62,\n 1,\n 4,\n 8,\n 3,\n 2,\n 9,\n 20,\n 6,\n 5,\n 6,\n 10,\n 0,\n 1,\n 2,\n 12,\n 17,\n 22,\n 33,\n 17,\n 9,\n 2,\n 16,\n 5,\n 3,\n 0,\n 18,\n 0,\n 2,\n 1,\n 2,\n 8,\n 1,\n 2,\n 2,\n 7,\n 2,\n 6,\n 8,\n 4,\n 3,\n 2,\n 33,\n 3,\n 2,\n 5,\n 14,\n 2,\n 3,\n 2,\n 8,\n 11,\n 5,\n 10,\n 16,\n 6,\n 1,\n 1,\n 8,\n 10,\n 2,\n 2,\n 7,\n 7,\n 2,\n 10,\n 22,\n 1,\n 4,\n 9,\n 0,\n 18,\n 3,\n 4,\n 14,\n 3,\n 1,\n 4,\n 5,\n 4,\n 14,\n 15,\n 3,\n 1,\n 347,\n 4,\n 4,\n 2,\n 87,\n 16,\n 4,\n 20,\n 18,\n 8,\n 8,\n 6,\n 2,\n 10,\n 25,\n 23,\n 10,\n 13,\n 9,\n 4,\n 12,\n 4,\n 26,\n 3,\n 39,\n 2,\n 16,\n 10,\n 0,\n 5,\n 5,\n 5,\n 3,\n 6,\n 10,\n 3,\n 7,\n 11,\n 1,\n 6,\n 4,\n 10,\n 36,\n 10,\n 13,\n 17,\n 1,\n 8,\n 3,\n 7,\n 4,\n 6,\n 1,\n 5,\n ...]"
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_length = [len(x) for x in df['Tokenized']]\n",
    "tokens_length"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-197-c40d3d87fbb6>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0msns\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdisplot\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtokens_length\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      2\u001B[0m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'sns' is not defined"
     ]
    }
   ],
   "source": [
    "sns.displot(tokens_length)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}